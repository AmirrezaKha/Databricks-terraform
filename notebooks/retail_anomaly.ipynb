{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64348023",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook\n",
    "\n",
    "# üîß Cell 1: Setup\n",
    "import mlflow, mlflow.sklearn\n",
    "from pyspark.sql import SparkSession\n",
    "from scripts.etl_retail import RetailETL\n",
    "from scripts.anomaly_retail import RetailAnomalyDetector\n",
    "\n",
    "spark = SparkSession.builder.appName(\"RetailPipeline\").getOrCreate()\n",
    "\n",
    "# üì¶ Cell 2: ETL\n",
    "etl = RetailETL()\n",
    "etl.run()\n",
    "\n",
    "# üß† Cell 3: Anomaly Detection\n",
    "with mlflow.start_run(run_name=\"Retail Anomaly\"):\n",
    "    detector = RetailAnomalyDetector(spark, method=\"isolation_forest\")\n",
    "    anomalies = detector.run()\n",
    "    mlflow.log_param(\"method\", detector.method)\n",
    "    mlflow.log_metric(\"num_anomalies\", len(anomalies))\n",
    "    mlflow.sklearn.log_model(detector.model, \"model\")\n",
    "    mlflow.log_artifact(\"scripts/anomaly_retail.py\")\n",
    "\n",
    "# üìä Cell 4: Display\n",
    "display(spark.table(\"main.etl.retail_monthly_sales\"))\n",
    "display(anomalies)\n",
    "\n",
    "# üîç Cell 5: MLflow Tracking\n",
    "print(f\"Run: {mlflow.active_run().info.run_id}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
